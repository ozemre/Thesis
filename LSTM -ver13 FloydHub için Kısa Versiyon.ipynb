{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import datetime\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.layers import Dense,Input, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras import optimizers\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "from random import gauss\n",
    "from random import seed\n",
    "from pandas import Series\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from random import randrange\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%m-%d %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/murat.ozemre/Documents/MOZEMRE-OZEL/Doktora/2017 Tez/Veri Analizi/Ver 3 Tez Izleme Calısmaları')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler_Type_Options = ['Normalizer', 'MinMaxScaler','MaxAbsScaler','RobustScaler','StandardScaler' ]\n",
    "#Scaler_Type_Options = ['Normalizer', 'MinMaxScaler' ]\n",
    "\n",
    "Product_Type_Options = [841810,841840,841850]\n",
    "Product=Product_Type_Options[2]\n",
    "ScalerType=Scaler_Type_Options[2]\n",
    "print(Product,ScalerType)\n",
    "\n",
    "MonthSeries=\"12\"\n",
    "MonthSeries_option=[\"1\",\"12\"]\n",
    "#MonthSeries_option=[\"12\",\"123\",\"1236\",\"1236_12\",\"__12\",\"__126\",\"__1263\",\"__12632\"]\n",
    "#MonthSeries_option=[\"12\",\"123\",\"1236\",\"1236_12\",\"__12\"]\n",
    "#X1hat.iloc[3:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setpartner(Product):\n",
    "    if Product==841810 :\n",
    "        IMP1=\"USA\"\n",
    "        IMP2=\"JPN\"\n",
    "        IMP3=\"FRA\"\n",
    "        IMP4=\"AUS\"\n",
    "        EXP1=\"POL\"\n",
    "        EXP2=\"KOR\"\n",
    "        EXP3=\"ITA\"\n",
    "    elif Product==841840 :\n",
    "        IMP1=\"USA\"\n",
    "        IMP2=\"JPN\"\n",
    "        IMP3=\"FRA\"\n",
    "        IMP4=\"DEU\"\n",
    "        EXP1=\"DEU\"\n",
    "        EXP2=\"NLD\"\n",
    "        EXP3=\"HUN\"\n",
    "    elif Product==841850 :\n",
    "        IMP1=\"USA\"\n",
    "        IMP2=\"AUS\"\n",
    "        IMP3=\"ITA\"\n",
    "        IMP4=\"IDN\"\n",
    "        EXP1=\"AUT\"\n",
    "        EXP2=\"CHZ\"\n",
    "        EXP3=\"ITA\"\n",
    "    \n",
    "    return IMP1,IMP2,IMP3,IMP4,EXP1,EXP2,EXP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readexcel(Product):\n",
    "    if Product==841810 :\n",
    "        Data_Core = pd.ExcelFile('Out_841810_CHN_UK_Data_Core_1236_12.xlsx')\n",
    "        Data_Core = Data_Core.parse('Sheet1', header=0,index_col=None, na_values=['NA'])\n",
    "    elif Product==841840:\n",
    "        Data_Core = pd.ExcelFile('Out_841840_CHN_UK_Data_Core_1236_12.xlsx')\n",
    "        Data_Core = Data_Core.parse('Sheet1', header=0,index_col=None, na_values=['NA'])\n",
    "    elif Product==841850:\n",
    "        Data_Core = pd.ExcelFile('Out_841850_CHN_UK_Data_Core_1236_12.xlsx')\n",
    "        Data_Core = Data_Core.parse('Sheet1', header=0,index_col=None, na_values=['NA'])\n",
    "    return Data_Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readexcel_hat(Product):\n",
    "    if Product==841810 :\n",
    "        Data_Core = pd.ExcelFile('Out_841810_CHN_UK_Data_Core_1236_12.xlsx')\n",
    "        Data_Core = Data_Core.parse('Sheet2', header=0,index_col=None, na_values=['NA'])\n",
    "    elif Product==841840:\n",
    "        Data_Core = pd.ExcelFile('Out_841840_CHN_UK_Data_Core_1236_12.xlsx')\n",
    "        Data_Core = Data_Core.parse('Sheet2', header=0,index_col=None, na_values=['NA'])\n",
    "    elif Product==841850:\n",
    "        Data_Core = pd.ExcelFile('Out_841850_CHN_UK_Data_Core_1236_12.xlsx')\n",
    "        Data_Core = Data_Core.parse('Sheet2', header=0,index_col=None, na_values=['NA'])\n",
    "    Data_Core=Data_Core.iloc[3:,:]\n",
    "    return Data_Core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_X(Product,Data_Core,Dimension):\n",
    "    if Dimension==\"1\":\n",
    "        X=Data_Core[\n",
    "    \n",
    "            ['CHN_GBR_{}'.format(Product),'CHN_GBR_{}-1REAL'.format(Product),\n",
    "               'CHN_World_{}-1'.format(Product), 'CHN_{}_{}-1'.format(IMP1,Product), 'CHN_{}_{}-1'.format(IMP2,Product),\n",
    "               'CHN_{}_{}-1'.format(IMP3,Product), 'CHN_{}_{}-1'.format(IMP4,Product), 'CHN_GBR_{}-1'.format(Product),\n",
    "               '{}_GBR_{}-1'. format(EXP1,Product), '{}_GBR_{}-1'. format(EXP2,Product), '{}_GBR_{}-1'. format(EXP3,Product), \n",
    "               'EPU_CHN-1','EPU_UK-1', 'EPU_World-1', \n",
    "               'BCI_CHN-1', 'CCI_CHN-1', 'CLI_CHN-1','GDP_CHN-1', \n",
    "               'BCI_GBR-1', 'CCI_GBR-1', 'CLI_GBR-1', 'GDP_GBR-1',\n",
    "               'PPI_CHN-1', 'PPI_GBR-1', 'CPI_CHN-1', 'CPI_GBR-1', \n",
    "               'CNY-1', 'GBP-1','World-1',\n",
    "               'Date','Year','Month']\n",
    "\n",
    "#             'CNY-1', 'GBP-1','World-1','Date','Year','Month']\n",
    "        ]\n",
    "                \n",
    "\n",
    "    elif Dimension==\"12\":\n",
    "        X=Data_Core[ \n",
    "    \n",
    "            ['CHN_GBR_{}'.format(Product),'CHN_GBR_{}-1REAL'.format(Product),\n",
    "               'CHN_World_{}-1'. format(Product), 'CHN_{}_{}-1'.format(IMP1,Product),'CHN_{}_{}-1'.format(IMP2,Product), \n",
    "               'CHN_{}_{}-1'.format(IMP3,Product), 'CHN_{}_{}-1'.format(IMP4,Product),'CHN_GBR_{}-1'. format(Product), \n",
    "       \n",
    "                'CHN_World_{}-2'. format(Product), 'CHN_{}_{}-2'.format(IMP1,Product),'CHN_{}_{}-2'.format(IMP2,Product), \n",
    "                'CHN_{}_{}-2'.format(IMP3,Product), 'CHN_{}_{}-2'.format(IMP4,Product),'CHN_GBR_{}-2'. format(Product), \n",
    "        \n",
    "                '{}_GBR_{}-1'. format(EXP1,Product), '{}_GBR_{}-1'. format(EXP2,Product),'{}_GBR_{}-1'. format(EXP3,Product),\n",
    "                '{}_GBR_{}-2'. format(EXP1,Product), '{}_GBR_{}-2'. format(EXP2,Product),'{}_GBR_{}-2'. format(EXP3,Product), \n",
    "        \n",
    "                'EPU_CHN-1', 'EPU_CHN-2', 'EPU_UK-1', 'EPU_UK-2','EPU_World-1', 'EPU_World-2', \n",
    "                'BCI_CHN-1', 'CCI_CHN-1', 'CLI_CHN-1','GDP_CHN-1', \n",
    "                'BCI_CHN-2', 'CCI_CHN-2', 'CLI_CHN-2', 'GDP_CHN-2',\n",
    "                'BCI_GBR-1', 'CCI_GBR-1', 'CLI_GBR-1', 'GDP_GBR-1', \n",
    "                'BCI_GBR-2','CCI_GBR-2', 'CLI_GBR-2', 'GDP_GBR-2', \n",
    "                'PPI_CHN-1', 'PPI_GBR-1','PPI_CHN-2', 'PPI_GBR-2', \n",
    "                'CPI_CHN-1', 'CPI_GBR-1', 'CPI_CHN-2','CPI_GBR-2', \n",
    "                'CNY-1', 'GBP-1', 'CNY-2', 'GBP-2', \n",
    "                'World-1', 'World-2',\n",
    "               'Date','Year','Month']\n",
    "    \n",
    "            ]\n",
    "\n",
    "    elif Dimension==\"123\":\n",
    "        X=Data_Core[ \n",
    "            ['CHN_GBR_{}'.format(Product), 'CHN_GBR_{}-1REAL'.format(Product),\n",
    "             'CHN_World_{}-1'. format(Product), 'CHN_{}_{}-1'.format(IMP1,Product),\n",
    "               'CHN_{}_{}-1'.format(IMP2,Product), 'CHN_{}_{}-1'.format(IMP3,Product), 'CHN_{}_{}-1'.format(IMP4,Product),\n",
    "               'CHN_GBR_{}-1'. format(Product), 'CHN_World_{}-2'. format(Product), 'CHN_{}_{}-2'.format(IMP1,Product),\n",
    "               'CHN_{}_{}-2'.format(IMP2,Product), 'CHN_{}_{}-2'.format(IMP3,Product), 'CHN_{}_{}-2'.format(IMP4,Product),\n",
    "               'CHN_GBR_{}-2'. format(Product), 'CHN_World_{}-3'. format(Product), 'CHN_{}_{}-3'.format(IMP1,Product),\n",
    "               'CHN_{}_{}-3'.format(IMP2,Product), 'CHN_{}_{}-3'.format(IMP3,Product), 'CHN_{}_{}-3'.format(IMP4,Product),\n",
    "               'CHN_GBR_{}-3'. format(Product), '{}_GBR_{}-1'. format(EXP1,Product), '{}_GBR_{}-1'. format(EXP2,Product),\n",
    "               '{}_GBR_{}-1'. format(EXP3,Product), '{}_GBR_{}-2'. format(EXP1,Product), '{}_GBR_{}-2'. format(EXP2,Product),\n",
    "               '{}_GBR_{}-2'. format(EXP3,Product), '{}_GBR_{}-3'. format(EXP1,Product), '{}_GBR_{}-3'. format(EXP2,Product),\n",
    "               '{}_GBR_{}-3'. format(EXP3,Product), 'EPU_CHN-1', 'EPU_CHN-2', 'EPU_CHN-3', 'EPU_UK-1',\n",
    "               'EPU_UK-2', 'EPU_UK-3', 'EPU_World-1', 'EPU_World-2', 'EPU_World-3',\n",
    "               'BCI_CHN-1', 'CCI_CHN-1', 'CLI_CHN-1', 'GDP_CHN-1', 'BCI_CHN-2',\n",
    "               'CCI_CHN-2', 'CLI_CHN-2', 'GDP_CHN-2', 'BCI_CHN-3', 'CCI_CHN-3',\n",
    "               'CLI_CHN-3', 'GDP_CHN-3', 'BCI_GBR-1', 'CCI_GBR-1', 'CLI_GBR-1',\n",
    "               'GDP_GBR-1', 'BCI_GBR-2', 'CCI_GBR-2', 'CLI_GBR-2', 'GDP_GBR-2',\n",
    "               'BCI_GBR-3', 'CCI_GBR-3', 'CLI_GBR-3', 'GDP_GBR-3', 'PPI_CHN-1',\n",
    "               'PPI_GBR-1', 'PPI_CHN-2', 'PPI_GBR-2', 'PPI_CHN-3', 'PPI_GBR-3',\n",
    "               'CPI_CHN-1', 'CPI_GBR-1', 'CPI_CHN-2', 'CPI_GBR-2', 'CPI_CHN-3',\n",
    "               'CPI_GBR-3', 'CNY-1', 'GBP-1', 'CNY-2', 'GBP-2', 'CNY-3', 'GBP-3',\n",
    "               'World-1', 'World-2', 'World-3',  \n",
    "                'Date','Year','Month']\n",
    "\n",
    "             ]\n",
    "    elif Dimension==\"1236\":\n",
    "        X=Data_Core[ \n",
    "\n",
    "            ['CHN_GBR_{}'.format(Product),'CHN_GBR_{}-1REAL'.format(Product),\n",
    "             'CHN_World_{}-1'. format(Product), 'CHN_{}_{}-1'.format(IMP1,Product),\n",
    "               'CHN_{}_{}-1'.format(IMP2,Product), 'CHN_{}_{}-1'.format(IMP3,Product), 'CHN_{}_{}-1'.format(IMP4,Product),\n",
    "               'CHN_GBR_{}-1'. format(Product), 'CHN_World_{}-2'. format(Product), 'CHN_{}_{}-2'.format(IMP1,Product),\n",
    "               'CHN_{}_{}-2'.format(IMP2,Product), 'CHN_{}_{}-2'.format(IMP3,Product), 'CHN_{}_{}-2'.format(IMP4,Product),\n",
    "               'CHN_GBR_{}-2'. format(Product), 'CHN_World_{}-3'. format(Product), 'CHN_{}_{}-3'.format(IMP1,Product),\n",
    "               'CHN_{}_{}-3'.format(IMP2,Product), 'CHN_{}_{}-3'.format(IMP3,Product), 'CHN_{}_{}-3'.format(IMP4,Product),\n",
    "               'CHN_GBR_{}-3'. format(Product), '{}_GBR_{}-1'. format(EXP1,Product), '{}_GBR_{}-1'. format(EXP2,Product),\n",
    "               '{}_GBR_{}-1'. format(EXP3,Product), '{}_GBR_{}-2'. format(EXP1,Product), '{}_GBR_{}-2'. format(EXP2,Product),\n",
    "               '{}_GBR_{}-2'. format(EXP3,Product), '{}_GBR_{}-3'. format(EXP1,Product), '{}_GBR_{}-3'. format(EXP2,Product),\n",
    "               '{}_GBR_{}-3'. format(EXP3,Product), 'EPU_CHN-1', 'EPU_CHN-2', 'EPU_CHN-3', 'EPU_UK-1',\n",
    "               'EPU_UK-2', 'EPU_UK-3', 'EPU_World-1', 'EPU_World-2', 'EPU_World-3',\n",
    "               'BCI_CHN-1', 'CCI_CHN-1', 'CLI_CHN-1', 'GDP_CHN-1', 'BCI_CHN-2',\n",
    "               'CCI_CHN-2', 'CLI_CHN-2', 'GDP_CHN-2', 'BCI_CHN-3', 'CCI_CHN-3',\n",
    "               'CLI_CHN-3', 'GDP_CHN-3', 'BCI_GBR-1', 'CCI_GBR-1', 'CLI_GBR-1',\n",
    "               'GDP_GBR-1', 'BCI_GBR-2', 'CCI_GBR-2', 'CLI_GBR-2', 'GDP_GBR-2',\n",
    "               'BCI_GBR-3', 'CCI_GBR-3', 'CLI_GBR-3', 'GDP_GBR-3', 'PPI_CHN-1',\n",
    "               'PPI_GBR-1', 'PPI_CHN-2', 'PPI_GBR-2', 'PPI_CHN-3', 'PPI_GBR-3',\n",
    "               'CPI_CHN-1', 'CPI_GBR-1', 'CPI_CHN-2', 'CPI_GBR-2', 'CPI_CHN-3',\n",
    "               'CPI_GBR-3', 'CNY-1', 'GBP-1', 'CNY-2', 'GBP-2', 'CNY-3', 'GBP-3',\n",
    "               'World-1', 'World-2', 'World-3',\n",
    "\n",
    "               'CHN_World_{}-6'. format(Product), 'CHN_{}_{}-6'.format(IMP1,Product), 'CHN_{}_{}-6'.format(IMP2,Product),\n",
    "               'CHN_{}_{}-6'.format(IMP3,Product), 'CHN_{}_{}-6'.format(IMP4,Product), 'CHN_GBR_{}-6'. format(Product),\n",
    "               '{}_GBR_{}-6'. format(EXP1,Product), '{}_GBR_{}-6'. format(EXP2,Product), '{}_GBR_{}-6'. format(EXP3,Product), \n",
    "               'EPU_CHN-6','EPU_UK-6', 'EPU_World-6', \n",
    "               'BCI_CHN-6', 'CCI_CHN-6', 'CLI_CHN-6','GDP_CHN-6', \n",
    "               'BCI_GBR-6', 'CCI_GBR-6', 'CLI_GBR-6', 'GDP_GBR-6',\n",
    "               'PPI_CHN-6', 'PPI_GBR-6', 'CPI_CHN-6', 'CPI_GBR-6', \n",
    "               'CNY-6', 'GBP-6','World-6',\n",
    "                'Date','Year','Month']\n",
    "\n",
    "             ]\n",
    "    elif Dimension==\"1236_12\":\n",
    "        X=Data_Core[ \n",
    "\n",
    "            ['CHN_GBR_{}'.format(Product),'CHN_GBR_{}-1REAL'.format(Product),\n",
    "             'CHN_World_{}-1'. format(Product), 'CHN_{}_{}-1'.format(IMP1,Product),\n",
    "               'CHN_{}_{}-1'.format(IMP2,Product), 'CHN_{}_{}-1'.format(IMP3,Product), 'CHN_{}_{}-1'.format(IMP4,Product),\n",
    "               'CHN_GBR_{}-1'. format(Product), 'CHN_World_{}-2'. format(Product), 'CHN_{}_{}-2'.format(IMP1,Product),\n",
    "               'CHN_{}_{}-2'.format(IMP2,Product), 'CHN_{}_{}-2'.format(IMP3,Product), 'CHN_{}_{}-2'.format(IMP4,Product),\n",
    "               'CHN_GBR_{}-2'. format(Product), 'CHN_World_{}-3'. format(Product), 'CHN_{}_{}-3'.format(IMP1,Product),\n",
    "               'CHN_{}_{}-3'.format(IMP2,Product), 'CHN_{}_{}-3'.format(IMP3,Product), 'CHN_{}_{}-3'.format(IMP4,Product),\n",
    "               'CHN_GBR_{}-3'. format(Product), '{}_GBR_{}-1'. format(EXP1,Product), '{}_GBR_{}-1'. format(EXP2,Product),\n",
    "               '{}_GBR_{}-1'. format(EXP3,Product), '{}_GBR_{}-2'. format(EXP1,Product), '{}_GBR_{}-2'. format(EXP2,Product),\n",
    "               '{}_GBR_{}-2'. format(EXP3,Product), '{}_GBR_{}-3'. format(EXP1,Product), '{}_GBR_{}-3'. format(EXP2,Product),\n",
    "               '{}_GBR_{}-3'. format(EXP3,Product), 'EPU_CHN-1', 'EPU_CHN-2', 'EPU_CHN-3', 'EPU_UK-1',\n",
    "               'EPU_UK-2', 'EPU_UK-3', 'EPU_World-1', 'EPU_World-2', 'EPU_World-3',\n",
    "               'BCI_CHN-1', 'CCI_CHN-1', 'CLI_CHN-1', 'GDP_CHN-1', 'BCI_CHN-2',\n",
    "               'CCI_CHN-2', 'CLI_CHN-2', 'GDP_CHN-2', 'BCI_CHN-3', 'CCI_CHN-3',\n",
    "               'CLI_CHN-3', 'GDP_CHN-3', 'BCI_GBR-1', 'CCI_GBR-1', 'CLI_GBR-1',\n",
    "               'GDP_GBR-1', 'BCI_GBR-2', 'CCI_GBR-2', 'CLI_GBR-2', 'GDP_GBR-2',\n",
    "               'BCI_GBR-3', 'CCI_GBR-3', 'CLI_GBR-3', 'GDP_GBR-3', 'PPI_CHN-1',\n",
    "               'PPI_GBR-1', 'PPI_CHN-2', 'PPI_GBR-2', 'PPI_CHN-3', 'PPI_GBR-3',\n",
    "               'CPI_CHN-1', 'CPI_GBR-1', 'CPI_CHN-2', 'CPI_GBR-2', 'CPI_CHN-3',\n",
    "               'CPI_GBR-3', 'CNY-1', 'GBP-1', 'CNY-2', 'GBP-2', 'CNY-3', 'GBP-3',\n",
    "               'World-1', 'World-2', 'World-3',\n",
    "\n",
    "               'CHN_World_{}-6'. format(Product), 'CHN_{}_{}-6'.format(IMP1,Product), 'CHN_{}_{}-6'.format(IMP2,Product),\n",
    "               'CHN_{}_{}-6'.format(IMP3,Product), 'CHN_{}_{}-6'.format(IMP4,Product), 'CHN_GBR_{}-6'. format(Product),   \n",
    "               '{}_GBR_{}-6'. format(EXP1,Product), '{}_GBR_{}-6'. format(EXP2,Product), '{}_GBR_{}-6'. format(EXP3,Product), \n",
    "               'EPU_CHN-6','EPU_UK-6', 'EPU_World-6', \n",
    "               'BCI_CHN-6', 'CCI_CHN-6', 'CLI_CHN-6','GDP_CHN-6', \n",
    "               'BCI_GBR-6', 'CCI_GBR-6', 'CLI_GBR-6', 'GDP_GBR-6',\n",
    "               'PPI_CHN-6', 'PPI_GBR-6', 'CPI_CHN-6', 'CPI_GBR-6', \n",
    "               'CNY-6', 'GBP-6','World-6',\n",
    "    \n",
    "               'CHN_World_{}-12'. format(Product), 'CHN_{}_{}-12'.format(IMP1,Product), 'CHN_{}_{}-12'.format(IMP2,Product),\n",
    "               'CHN_{}_{}-12'.format(IMP3,Product), 'CHN_{}_{}-12'.format(IMP4,Product), 'CHN_GBR_{}-12'. format(Product),       \n",
    "               '{}_GBR_{}-12'. format(EXP1,Product), '{}_GBR_{}-12'. format(EXP2,Product), '{}_GBR_{}-12'. format(EXP3,Product), \n",
    "               'EPU_CHN-12','EPU_UK-12', 'EPU_World-12', \n",
    "               'BCI_CHN-12', 'CCI_CHN-12', 'CLI_CHN-12','GDP_CHN-12', \n",
    "               'BCI_GBR-12', 'CCI_GBR-12', 'CLI_GBR-12', 'GDP_GBR-12',\n",
    "               'PPI_CHN-12', 'PPI_GBR-12', 'CPI_CHN-12', 'CPI_GBR-12', \n",
    "               'CNY-12', 'GBP-12','World-12',\n",
    "                'Date','Year','Month']\n",
    "   \n",
    "             ]\n",
    "\n",
    "    X=X.dropna()    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MonthSeries=\"1\" # veya \"2\"\n",
    "\n",
    "for Product in Product_Type_Options:\n",
    "    partner=setpartner(Product)\n",
    "  \n",
    "    IMP1=partner[0]\n",
    "    IMP2=partner[1]\n",
    "    IMP3=partner[2]\n",
    "    IMP4=partner[3]\n",
    "    EXP1=partner[4]\n",
    "    EXP2=partner[5]\n",
    "    EXP3=partner[6]\n",
    "    \n",
    "    Data_Core=readexcel(Product)\n",
    "    Data_Core_hat=readexcel_hat(Product)\n",
    "#    Z=set_z(Product,Data_Core)\n",
    "    print(Product)\n",
    "    if Product==841810 :\n",
    "        X1=set_X(Product,Data_Core,MonthSeries)\n",
    "        y1=X1['CHN_GBR_{}'.format(Product)]\n",
    "        z1=X1[['Date','Year','Month']]\n",
    "        X1=X1.drop(['CHN_GBR_{}'.format(Product),'CHN_GBR_{}-1REAL'.format(Product),'Date','Year','Month'], axis=1)\n",
    "\n",
    "        X1hat=set_X(Product,Data_Core_hat,MonthSeries)\n",
    "        y1hat=X1hat['CHN_GBR_{}'.format(Product)]\n",
    "        z1hat=X1hat[['Date','Year','Month']]\n",
    "        X1hat=X1hat.drop(['CHN_GBR_{}'.format(Product),'Date','Year','Month'], axis=1)\n",
    "\n",
    "        print('X1',X1.shape, y1.shape,'X1hat', X1hat.shape, y1hat.shape)\n",
    "        \n",
    "    elif Product==841840 :\n",
    "\n",
    "        X2=set_X(Product,Data_Core,MonthSeries)\n",
    "        y2=X2['CHN_GBR_{}'.format(Product)]\n",
    "        z2=X2[['Date','Year','Month']]\n",
    "        X2=X2.drop(['CHN_GBR_{}'.format(Product),'CHN_GBR_{}-1REAL'.format(Product),'Date','Year','Month'], axis=1)\n",
    "\n",
    "        X2hat=set_X(Product,Data_Core_hat,MonthSeries)\n",
    "        y2hat=X2hat['CHN_GBR_{}'.format(Product)]\n",
    "        z2hat=X2hat[['Date','Year','Month']]\n",
    "        X2hat=X2hat.drop(['CHN_GBR_{}'.format(Product),'Date','Year','Month'], axis=1)\n",
    "\n",
    "        print('X2',X2.shape, y2.shape,'X2hat', X2hat.shape, y2hat.shape)\n",
    "    elif Product==841850 :\n",
    "        X3=set_X(Product,Data_Core,MonthSeries)\n",
    "        y3=X3['CHN_GBR_{}'.format(Product)]\n",
    "        z3=X3[['Date','Year','Month']]\n",
    "        X3=X3.drop(['CHN_GBR_{}'.format(Product),'CHN_GBR_{}-1REAL'.format(Product),'Date','Year','Month'], axis=1)\n",
    "\n",
    "        X3hat=set_X(Product,Data_Core_hat,MonthSeries)\n",
    "        y3hat=X3hat['CHN_GBR_{}'.format(Product)]\n",
    "        z3hat=X3hat[['Date','Year','Month']]\n",
    "        X3hat=X3hat.drop(['CHN_GBR_{}'.format(Product),'Date','Year','Month'], axis=1)\n",
    "\n",
    "        print('X3',X3.shape, y3.shape,'X3hat', X3hat.shape, y3hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X1.to_excel('X1.xlsx',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TrainTestSplit(rs,X,y,date,th,random_split):\n",
    "    split_succesfull='TRUE'\n",
    "    values = X.values\n",
    "    values = values.astype('float32')\n",
    "    scaler_x= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_x = scaler_x.fit_transform(values)\n",
    "    scaled_value_x = pd.DataFrame(data=scaled_value_x[:,:])\n",
    "\n",
    "    values = y.values\n",
    "    values = values.astype('float32')\n",
    "    scaler_y= MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaled_value_y = scaler_y.fit_transform(values)\n",
    "    scaled_value_y = pd.DataFrame(data=scaled_value_y)\n",
    "\n",
    "    if random_split =='TRUE':\n",
    "        train_X, test_X, train_y, test_y = train_test_split(scaled_value_x.values,scaled_value_y.values,\n",
    "                                                        test_size=0.2,random_state=rs, \n",
    "                                                        stratify=date['Month']\n",
    "                                                       )\n",
    "\n",
    "        \n",
    "\n",
    "    elif random_split =='FALSE':\n",
    "        train_lenght=int(len(X)*0.8)\n",
    "        test_lenght=len(X)-train_lenght\n",
    "        \n",
    "        train_X=scaled_value_x.iloc[0:train_lenght,:].values\n",
    "        test_X=scaled_value_x.iloc[train_lenght:len(X),:].values \n",
    "        \n",
    "        train_y=scaled_value_y.iloc[0:train_lenght].values \n",
    "        test_y=scaled_value_y.iloc[train_lenght:len(X)].values\n",
    "        \n",
    "#        train_y_Analiz= train_y\n",
    "#        test_y_Analiz=test_y\n",
    "  \n",
    "    train_y_Analiz=pd.DataFrame(data=train_y[:,:])\n",
    "    test_y_Analiz=pd.DataFrame(data=test_y[:,:])\n",
    "    \n",
    "#    Analiz(scaled_value_y)\n",
    "#    Analiz(train_y_Analiz)\n",
    "#    Analiz(test_y_Analiz)\n",
    "    mean_scaled_y=scaled_value_y.describe().iloc[1].values\n",
    "    mean_train_y=train_y_Analiz.describe().iloc[1].values\n",
    "    mean_test_y=test_y_Analiz.describe().iloc[1].values\n",
    "    \n",
    "    perc=abs((mean_train_y-mean_scaled_y)/mean_scaled_y)*100\n",
    "    \n",
    "    if perc > th:\n",
    "    \n",
    "#        print('Split is not succesfull') \n",
    "        split_succesfull='FALSE'\n",
    "    \n",
    "#    print('mean=', mean_scaled_y,'mean_train_y=',mean_train_y, 'perc=', perc)\n",
    "#    print('diffence=', (mean_train_y-mean_scaled_y))\n",
    "    \n",
    "#    print('mean=', scaled_value_y.describe().iloc[1])\n",
    "    #print(scaled_value_y.describe()) #,train_y_Analiz.describe(),test_y_Analiz.describe()[1])\n",
    "    \n",
    "    #a.to_excel('Dagılım_Kontrolu_icin.xlsx',index = False)\n",
    "    \n",
    "    return train_X, test_X, train_y, test_y, scaler_x, scaler_y,scaled_value_y.describe(),split_succesfull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y=y3\n",
    "X=X3\n",
    "date=z3\n",
    "repeats=1\n",
    "rs=random.randint(1,100)\n",
    "rs=42\n",
    "print(rs)\n",
    "#Threshold Setting for warning\n",
    "th=2.5\n",
    "random_split='FALSE'\n",
    "SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "for r in range(repeats):\n",
    "    rs=random.randint(1,100)\n",
    "    print(rs)\n",
    "    SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "    \n",
    "#Feature Reduction için % oran %0 hepisini alıyor.    \n",
    "#percentile=50\n",
    "percentile=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.to_excel('X2Split.xlsx',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HIC AYAR YAPMADAN FARKLI SPLIT YAPARAK RF CALISMASI\n",
    "Dort Farklı Calısma Yapıldı\n",
    "1. Aylık Stratify olmadan her 3 urun kodu için çalıştırıldı\n",
    "2. Aylık Stratify yapılarak her 3 ürün kodu için çalıştırıldı\n",
    "3. Aylık Stratify yapılarak aylık fark verisi üzerinden (Xhat) her 3 ürün kodu için çalıştırıldı \n",
    "    R2 gercek değeri alındı.\n",
    "4. Aylık Stratify yapılarak aylık fark verisi üzerinden (Xhat) her 3 ürün kodu için çalıştırıldı \n",
    "    R2 o ayın gerçek değerine göre ayarlanarak alındı.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def experiment_RF(repeats,param,est,min_leaf,random,feat,max_leaf,min_weight,min_impurity,train_X, test_X, train_y, test_y,scaler_x,scaler_y):\n",
    "\n",
    "    \n",
    "    error_rmse = list()\n",
    "    error_r2hat = list()\n",
    "    error_r2 = list()\n",
    "    for r in range(repeats):\n",
    "        \n",
    "        if param== 'TRUE':\n",
    "            rfc_model=RandomForestRegressor(n_estimators=est,\n",
    "                              min_samples_leaf=min_leaf,\n",
    "                          #    random_state =random,\n",
    "                              max_features=feat,\n",
    "                              max_leaf_nodes=max_leaf,\n",
    "                              min_weight_fraction_leaf =min_weight,\n",
    "                              min_impurity_split=min_impurity\n",
    "                             )\n",
    "        elif param== 'FALSE':\n",
    "            rfc_model=RandomForestRegressor()\n",
    "\n",
    "        RandomForestRegressor.fit(rfc_model,train_X,train_y)\n",
    "        \n",
    "        # make a prediction\n",
    "        y_predict_test = rfc_model.predict(test_X)\n",
    "        y_predict_train = rfc_model.predict(train_X)\n",
    "\n",
    "\n",
    "        #test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "#        test_X_reshaped = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "        inv_x_test = scaler_x.inverse_transform(test_X)\n",
    "        inv_x_test = pd.DataFrame(data=inv_x_test[:,:])\n",
    "\n",
    "\n",
    "        # invert scaling for forecast\n",
    "        inv_y_predict_test = scaler_y.inverse_transform(y_predict_test)\n",
    "#        inv_y_predict_test = inv_y_predict_test[:,0]\n",
    "        inv_y_predict_train = scaler_y.inverse_transform(y_predict_train)\n",
    "#        inv_y_predict_train = inv_y_predict_train[:,0]\n",
    "\n",
    "        # invert scaling for actual\n",
    "        y_test = test_y.reshape((len(test_y), 1))\n",
    "        inv_y_test = scaler_y.inverse_transform(test_y)\n",
    "        inv_y_test = inv_y_test[:,0]\n",
    "\n",
    "        y_train = train_y.reshape((len(train_y), 1))\n",
    "        inv_y_train = scaler_y.inverse_transform(train_y)\n",
    "        inv_y_train = inv_y_train[:,0]\n",
    "\n",
    "        # calculate RMSE for DIFFERENCE\n",
    "        rmse_test = sqrt(mean_squared_error(inv_y_test, inv_y_predict_test))\n",
    "#        print('Test RMSE: %.3f' % rmse_test)\n",
    "        R2_test=int(1000*(metrics.r2_score(inv_y_test, inv_y_predict_test)))/1000\n",
    "#        print('R2_test: %.3f' % R2_test)\n",
    "\n",
    "        rmse_train = sqrt(mean_squared_error(inv_y_train, inv_y_predict_train))\n",
    "#        print('Train RMSE: %.3f' % rmse_train)\n",
    "        R2_train=int(1000*(metrics.r2_score(inv_y_train, inv_y_predict_train)))/1000\n",
    "#        print('R2_train: %.3f' % R2_train)\n",
    "\n",
    "        # calculate RMSE for REAL VALUE\n",
    "\n",
    "        real_y_test= inv_x_test.iloc[:,0]+inv_y_test\n",
    "        real_y_predict_test=inv_x_test.iloc[:,0]+inv_y_predict_test\n",
    "        \n",
    "        real_rmse_test = sqrt(mean_squared_error(real_y_test, real_y_predict_test))\n",
    "#        print('Test RMSE: %.3f' % real_rmse_test)\n",
    "        real_R2_test=int(1000*(metrics.r2_score(real_y_test, real_y_predict_test)))/1000\n",
    "#        print('R2_test: %.3f' % real_R2_test)\n",
    "        \n",
    "        error_rmse.append(real_rmse_test)\n",
    "        error_r2hat.append(real_R2_test)\n",
    "        error_r2.append(R2_test)\n",
    "        \n",
    "#        plt.gcf().clear()\n",
    "#        plt.figure(figsize=(5.5, 5.5))\n",
    "#        plt.plot(range(len(inv_y_test)), inv_y_test, linestyle='-', marker='*', color='r')\n",
    "#        plt.plot(range(len(inv_y_predict_test)), inv_y_predict_test, linestyle='-', marker='.', color='b')\n",
    "#        plt.legend(['Actual','Predicted'], loc=2)\n",
    "#        plt.title('Actual vs Predicted for {}'.format(y.name))\n",
    "#        plt.ylabel('Trade Value')\n",
    "#        plt.xlabel('Index')\n",
    "#        plt.savefig('Data/RF-LinePlt{} ,{} est,{} min_leaf,{} rs_for split,{} max_leaf, {} min_weight,{}min_impurity, {} R2.png'.format(y.name,\n",
    "#                                est,min_leaf,random,feat,max_leaf,min_weight,min_impurity,R2_test), format='png', dpi=300)\n",
    "       \n",
    "\n",
    "        \n",
    "        \n",
    "    return error_rmse,error_r2,error_r2hat,train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repeats=3\n",
    "random_range_for_split=50\n",
    "rs=random.randint(1,100)\n",
    "#rs=12\n",
    "results = DataFrame()\n",
    "results_exp = DataFrame()\n",
    "results_split= DataFrame()\n",
    "\n",
    "est=10000\n",
    "min_leaf=5\n",
    "feat=\"auto\"\n",
    "max_leaf=100\n",
    "min_weight=0.00001\n",
    "min_impurity=0.001\n",
    "\n",
    "param='TRUE'\n",
    "\n",
    "for r in range (random_range_for_split):\n",
    "\n",
    "#for r in range(repeats):\n",
    "    rs=random.randint(1,100)\n",
    "#    rs=42\n",
    "    print(rs)\n",
    "    SplitData=TrainTestSplit(rs,X,y,date,th,random_split)\n",
    "\n",
    "    \n",
    "    train_X=SplitData[0] \n",
    "    test_X=SplitData[1] \n",
    "    train_y=SplitData[2] \n",
    "    test_y=SplitData[3]\n",
    "    scaler_x=SplitData[4]\n",
    "    scaler_y=SplitData[5]\n",
    "    split_succesfull=SplitData[7]\n",
    "    print(split_succesfull)\n",
    "\n",
    "    experiment_result=experiment_RF(repeats,param,est,min_leaf,rs,\n",
    "                                    feat,max_leaf,min_weight,min_impurity,\n",
    "                                    train_X, test_X, train_y, test_y,scaler_x,scaler_y)[1]\n",
    "    \n",
    "#Xhat için analiz yapıldığı ve Adjusted R2 hesaplandığı zaman [2] nolu output kullanılıyor \n",
    "#                                    train_X, test_X, train_y, test_y,scaler_x,scaler_y)[2]\n",
    "\n",
    "    results[str(r)]= experiment_result\n",
    "    results_exp[split_succesfull]= experiment_result\n",
    "    results_split=pd.concat([results_split,results_exp])\n",
    "    print ('results split',results_split)\n",
    "\n",
    "results_randomnumber_bins=results\n",
    "resultvalues=results.values\n",
    "results_all=resultvalues.reshape((random_range_for_split*repeats,1))\n",
    "results_all=pd.DataFrame(data=results_all[:,:])\n",
    "\n",
    "#max_R2=results_all.describe().iloc[7,:]\n",
    "#std=results_all.describe().iloc[2,:]\n",
    "#mean=results_all.describe().iloc[1,:]\n",
    "\n",
    "mean=results_all.describe().values[1]\n",
    "std=results_all.describe().values[2]\n",
    "max_R2=results_all.describe().values[7]\n",
    "\n",
    "results_all.hist()\n",
    "plt.title('{} and with split threshold {} for {} different run'.format(y.name,th,random_range_for_split))\n",
    "plt.axis([0, 1, 0, 400])\n",
    "plt.xlabel('mean {}, std {}, max_value{}'.format(mean,std,max_R2))\n",
    "#plt.savefig('Distiribution_without_Tuning\\Histogram Plot R2 for {} and with (non stratify) split threshold {} for {} different run.png'.format(y.name,th,random_range_for_split))\n",
    "plt.savefig('Distiribution_without_Tuning\\Histogram Plot R2 for {} and with (rs=random) split threshold {} and {} param for {} different run.png'.format(y.name,th,param,random_range_for_split))\n",
    "\n",
    "pyplot.show()\n",
    "\n",
    "plt.gcf().clear()\n",
    "plt.title('{} and with split threshold {}'.format(y.name,th))\n",
    "\n",
    "results_split.boxplot()\n",
    "#plt.savefig('Distiribution_without_Tuning\\Box Plot R2 for {} and with (non stratify) split threshold {} for {} different run.png'.format(y.name,th,random_range_for_split), format='png', dpi=300)\n",
    "plt.savefig('Distiribution_without_Tuning\\Box Plot R2 for {} and with (rs=random)split threshold {} for {} different run.png'.format(y.name,th,random_range_for_split), format='png', dpi=300)\n",
    "\n",
    "pyplot.show()                                   \n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#sonuc=pd.concat([sonuc,calıstır_randomforest(X_train, X_test, y_train, y_test,scaler_y,Product,MonthSerie,ScalerType)])\n",
    "\n",
    "#max_R2=int((sonuc['R2'].max())*1000)/1000\n",
    "#filename='Out_Random_Predict_Results_{one}_Product{two}_{four}perc_with max{tre}'.format(one=datetime.now().strftime('Date_%m-%d_Time%H_%M'),\n",
    "#                                                                                      two=Product,tre=max_R2,four=percentile)\n",
    "#sonuc.to_excel('{}.xlsx'.format(filename),index = False)      \n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ince Ayar Yapılmadan once (Spilt için RS sabit) ve tuning sonrasındaki karşılaştırma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
